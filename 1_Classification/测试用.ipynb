{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "class DealDataset(Dataset):\n",
    "    def __init__(self，path):\n",
    "        wine_train = np.load(path)# 使用numpy读取数据\n",
    "        self.x_data = torch.from_numpy(wine_train[:, 0:-1])\n",
    "        self.y_data = torch.from_numpy(wine_train[:, -1])\n",
    "        self.x_data = self.x_data.float()\n",
    "        self.y_data = self.y_data.long()\n",
    "        self.len = wine_train.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "#加载数据\n",
    "dealDataset = DealDataset(\"./data_wine.npy\")\n",
    "\n",
    "train_loader = DataLoader(dataset=dealDataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=13, out_features=7, bias=True)\n",
      "  (fc2): Linear(in_features=7, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#构建神经网络\n",
    "class Net(nn.Module):#继承父类\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #构建feed forward网络\n",
    "        self.fc1 = nn.Linear(13, 7)  \n",
    "        self.fc2 = nn.Linear(7, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        out = F.log_softmax(x, dim=1)\n",
    "        return out\n",
    "    \n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.02) #设置优化器参数,lr=0.002指的是学习率的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.1440, grad_fn=<NllLossBackward>)\n",
      "0 tensor(1.0739, grad_fn=<NllLossBackward>)\n",
      "0 tensor(1.0429, grad_fn=<NllLossBackward>)\n",
      "0 tensor(1.1322, grad_fn=<NllLossBackward>)\n",
      "0 tensor(1.0854, grad_fn=<NllLossBackward>)\n",
      "1 tensor(1.0736, grad_fn=<NllLossBackward>)\n",
      "1 tensor(1.0866, grad_fn=<NllLossBackward>)\n",
      "1 tensor(1.0896, grad_fn=<NllLossBackward>)\n",
      "1 tensor(1.1317, grad_fn=<NllLossBackward>)\n",
      "1 tensor(1.1496, grad_fn=<NllLossBackward>)\n",
      "2 tensor(1.0555, grad_fn=<NllLossBackward>)\n",
      "2 tensor(1.1143, grad_fn=<NllLossBackward>)\n",
      "2 tensor(1.1147, grad_fn=<NllLossBackward>)\n",
      "2 tensor(1.1059, grad_fn=<NllLossBackward>)\n",
      "2 tensor(1.0842, grad_fn=<NllLossBackward>)\n",
      "3 tensor(1.0803, grad_fn=<NllLossBackward>)\n",
      "3 tensor(1.1041, grad_fn=<NllLossBackward>)\n",
      "3 tensor(1.0561, grad_fn=<NllLossBackward>)\n",
      "3 tensor(1.1397, grad_fn=<NllLossBackward>)\n",
      "3 tensor(1.1444, grad_fn=<NllLossBackward>)\n",
      "4 tensor(1.0883, grad_fn=<NllLossBackward>)\n",
      "4 tensor(1.0642, grad_fn=<NllLossBackward>)\n",
      "4 tensor(1.1363, grad_fn=<NllLossBackward>)\n",
      "4 tensor(1.1084, grad_fn=<NllLossBackward>)\n",
      "4 tensor(1.0255, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # 将数据从 train_loader 中读出来,一次读取的样本数是64个\n",
    "        inputs, labels = data\n",
    "        # 接下来就是跑模型的环节了，我们这里使用print来代替\n",
    "        optimizer.zero_grad()\n",
    "        out = net(inputs)\n",
    "        #loss\n",
    "        loss = F.nll_loss(out,labels)\n",
    "        loss.backward()\n",
    "        #update\n",
    "        optimizer.step()\n",
    "        if batch_size % 32 == 0:\n",
    "            print(epoch, loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python pytorch",
   "language": "python",
   "name": "pytorch_envs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
